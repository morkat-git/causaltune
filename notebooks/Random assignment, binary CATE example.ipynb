{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f30c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random assignment, binary CATE example\n",
    "\n",
    "This is a fully worked-out notebook showing how you would apply auto-causality to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6eaac69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the below checks for whether we run dowhy, auto-causality, and FLAML from source\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "try:\n",
    "    import dowhy\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
    "\n",
    "try:\n",
    "    import flaml\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"FLAML\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53241021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this makes the notebook expand to full width of the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed9b5f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n// turn off scrollable windows for large output\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "// turn off scrollable windows for large output\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da208ce6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "from auto_causality import AutoCausality\n",
    "from auto_causality.datasets import synth_ihdp\n",
    "from auto_causality.data_utils import preprocess_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637c532",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model fitting & scoring\n",
    "Here we fit a (selection of) model(s) to the data and score them with the normalized ERUPT metric (chosen to specifically look for differences in impact across customers) on held-out data.\n",
    "\n",
    "We import an example dataset and pre-process it. The pre-processing fills in the NaNs and one-hot-encodes all categorical and int variables.\n",
    "\n",
    "If you don't want an int variable to be one-hot-encoded, please cast it to float before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0751bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = synth_ihdp()\n",
    "treatment = data.treatment\n",
    "targets = data.outcomes\n",
    "data_df, features_X, features_W = preprocess_dataset(data.data, treatment, targets)\n",
    "\n",
    "outcome = targets[0]\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e4721b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     treatment  y_factual        x1        x2        x3        x4        x5  \\\n",
      "277        1.0   4.474727 -0.439977 -0.202946  0.011465 -0.879606 -0.254086   \n",
      "479        0.0   2.261552  0.532750  0.596582 -1.477987  0.161703  1.058775   \n",
      "451        1.0   6.417115 -0.548057  0.596582  1.500917 -0.879606 -1.191844   \n",
      "687        0.0   3.443494  0.921840  0.596582 -0.360898 -0.879606 -1.066810   \n",
      "514        0.0   2.134798 -1.088461 -1.402238  1.128554  1.203011 -0.441638   \n",
      "\n",
      "           x6   x7   x8  ...  x17  x18  x19  x20  x21  x22  x23  x24  x25  \\\n",
      "277 -1.023402  1.0  1.0  ...  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "479 -0.857787  1.0  0.0  ...  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "451 -0.857787  1.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "687  0.632754  0.0  0.0  ...  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "514 -0.857787  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "\n",
      "     random  \n",
      "277     1.0  \n",
      "479     1.0  \n",
      "451     1.0  \n",
      "687     1.0  \n",
      "514     1.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e8ec6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fitting the model is as simple as calling AutoCausality.fit(), with the only required parameter apart from the data being the amount of time you want to give the optimizer, either for the whole run (`time_budget`) or per FLAML component model (`components_time_budget`), or both.\n",
    "\n",
    "If you want to use specific estimators, comment in the `estimator_list` below to include any estimators whose full name contains any of the elements of `estimator_list`.\n",
    "\n",
    "The other allowed values are `all` and `auto`, the default is `auto`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ac = AutoCausality(\n",
    "#     time_budget=600,# it's best to specify either time_budget or components_time_budget, and let the other one be inferred\n",
    "    # estimator_list=[\n",
    "    #         \"Dummy\",\n",
    "    #         \"SparseLinearDML\",\n",
    "    #         \"ForestDRLearner\",\n",
    "    #         \"TransformedOutcome\",\n",
    "    #         \"CausalForestDML\",\n",
    "#             \".LinearDML\",\n",
    "#             \"DomainAdaptationLearner\",\n",
    "#             \"SLearner\",\n",
    "#             \"XLearner\",\n",
    "#             \"TLearner\",\n",
    "#             \"Ortho\",\n",
    "        # ],\n",
    "    metric=\"norm_erupt\",\n",
    "    verbose=3,\n",
    "    components_verbose=2,\n",
    "    components_time_budget=15,\n",
    ")\n",
    "\n",
    "\n",
    "# run autocausality\n",
    "ac.fit(train_df, treatment, outcome, features_W, features_X)\n",
    "\n",
    "# return best estimator\n",
    "print(f\"Best estimator: {ac.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"best config: {ac.best_config}\")\n",
    "# best score:\n",
    "print(f\"best score: {ac.best_score}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After running a fit, you can resume it without losing past results, for example if you want to search over extra estimators."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we can now resume the fit to continue with the init_cfgs which we haven't tried yet\n",
    "# ac.fit(train_df, treatment, outcome, features_W, features_X,resume=True)\n",
    "# # return best estimator\n",
    "# print(f\"Best estimator: {ac.best_estimator}\")\n",
    "# # config of best estimator:\n",
    "# print(f\"best config: {ac.best_config}\")\n",
    "# # best score:\n",
    "# print(f\"best score: {ac.best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# score all estimators on the test set, which we've kept aside up till now\n",
    "\n",
    "for est_name, scr in ac.scores.items():\n",
    "    causal_estimate = scr['estimator']\n",
    "    scr['scores']['test'] = ac.scorer.make_scores(causal_estimate, test_df, ac.problem, ac.metrics_to_report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "colors = ([matplotlib.colors.CSS4_COLORS['black']] +\n",
    "    list(matplotlib.colors.TABLEAU_COLORS) + [\n",
    "    matplotlib.colors.CSS4_COLORS['lime'],\n",
    "    matplotlib.colors.CSS4_COLORS['yellow'],\n",
    "    matplotlib.colors.CSS4_COLORS['pink']\n",
    "])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title(outcome)\n",
    "\n",
    "m1 = \"ate\"\n",
    "m2 = \"norm_erupt\"\n",
    "\n",
    "for (est, scr), col in zip(ac.scores.items(),colors):\n",
    "    try:\n",
    "        sc = [scr[\"scores\"]['train'][m1], scr[\"scores\"]['validation'][m1], scr[\"scores\"]['test'][m1]]\n",
    "        crv = [scr[\"scores\"]['train'][m2], scr[\"scores\"]['validation'][m2], scr[\"scores\"]['test'][m2]]\n",
    "        plt.plot(sc, crv, color=col, marker=\"o\", label=est)\n",
    "        plt.scatter(sc[1:2],crv[1:2], c=col, s=70, label=\"_nolegend_\" )\n",
    "        plt.scatter(sc[2:],crv[2:], c=col, s=120, label=\"_nolegend_\" )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "plt.xlabel(m1)\n",
    "plt.ylabel(m2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scr = ac.scores[ac.best_estimator]\n",
    "intrp = scr[\"scores\"]['validation']['intrp']\n",
    "plt.figure(figsize=(15, 7))\n",
    "intrp.plot(feature_names=intrp.feature_names, fontsize=10)\n",
    "plt.title(f\"{ac.best_estimator}_{outcome}\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# and now let's visualize feature importances!\n",
    "from auto_causality.shap import shap_values\n",
    "\n",
    "# Shapley values calculation can be slow so let's subsample\n",
    "this_df = test_df.sample(100)\n",
    "\n",
    "if \"Dummy\" not in ac.best_estimator:\n",
    "    scr = ac.scores[ac.best_estimator]\n",
    "    print(outcome, ac.best_estimator)\n",
    "    est = ac.model\n",
    "    shaps = shap_values(est, this_df)\n",
    "\n",
    "    plt.title(outcome + '_' + ac.best_estimator.split('.')[-1])\n",
    "    shap.summary_plot(shaps, this_df[est.estimator._effect_modifier_names])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The best performing model is {ac.best_estimator} which doesn't depend on features\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot out-of sample difference of outcomes between treated and untreated for the points where a model predicts positive vs negative impact\n",
    "my_est = ac.best_estimator\n",
    "stats = []\n",
    "\n",
    "v = ac.scores[my_est]['scores']['test']['values']\n",
    "\n",
    "sts = ac.scorer.group_ate(test_df.reset_index(), v['norm_policy'])\n",
    "\n",
    "display(sts)\n",
    "\n",
    "\n",
    "colors = (matplotlib.colors.CSS4_COLORS['black'],\n",
    "    matplotlib.colors.CSS4_COLORS['red'],\n",
    "    matplotlib.colors.CSS4_COLORS['blue'])\n",
    "\n",
    "grp = sts[\"policy\"].unique()\n",
    "\n",
    "for i,(p,c) in enumerate(zip(grp, colors)):\n",
    "    st = sts[sts[\"policy\"] == p]\n",
    "    plt.errorbar(np.array(range(len(st))) +0.1*i, st[\"mean\"].values[0],  yerr = st[\"std\"].values[0], color=c)\n",
    "plt.legend(grp)\n",
    "plt.grid(True)\n",
    "plt.title(my_est.split('.')[-1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "097ab21372014822a933e162c070a8b1f7b350c74f9545016f0c559973f73b9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}