{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistc ERUPT in CATE Setting\n",
    "\n",
    "Let's suppose we have two treatments for a medical condition, and we want to evaluate their effectiveness for patients segmented by age group. Our goal is to use probabilistic ERUPT to compare different models that estimate CATE.\n",
    "\n",
    "#### Treatments\n",
    "\n",
    "- **Treatment A**: Medication A\n",
    "- **Treatment B**: Medication B\n",
    "\n",
    "#### Data from Clinical Trials\n",
    "\n",
    "Here is hypothetical data showing patient outcomes after receiving each treatment, segmented by age group:\n",
    "\n",
    "| Patient | Age Group | Treatment | Outcome |\n",
    "|---------|-----------|-----------|---------|\n",
    "| 1       | Young     | A         | 5       |\n",
    "| 2       | Young     | A         | 3       |\n",
    "| 3       | Young     | B         | 2       |\n",
    "| 4       | Old       | B         | 4       |\n",
    "| 5       | Old       | A         | 6       |\n",
    "| 6       | Old       | B         | 5       |\n",
    "\n",
    "#### Model Predictions\n",
    "\n",
    "Two different models provide CATE estimates (impact) and uncertainties (standard deviations) for each treatment, segmented by age group.\n",
    "\n",
    "**Model 1 Estimates:**\n",
    "\n",
    "| Age Group | Treatment | Estimated Impact | Std Deviation |\n",
    "|-----------|-----------|------------------|---------------|\n",
    "| Young     | A         | 4.5              | 1.0           |\n",
    "| Young     | B         | 3.5              | 0.5           |\n",
    "| Old       | A         | 5.5              | 0.8           |\n",
    "| Old       | B         | 4.0              | 0.6           |\n",
    "\n",
    "**Model 2 Estimates:**\n",
    "\n",
    "| Age Group | Treatment | Estimated Impact | Std Deviation |\n",
    "|-----------|-----------|------------------|---------------|\n",
    "| Young     | A         | 4.0              | 0.8           |\n",
    "| Young     | B         | 4.0              | 0.8           |\n",
    "| Old       | A         | 5.0              | 0.7           |\n",
    "| Old       | B         | 5.0              | 0.7           |\n",
    "\n",
    "### Probabilistic ERUPT Process in CATE Setting\n",
    "\n",
    "Here’s how the process can be adapted to evaluate and compare these models in the CATE setting:\n",
    "\n",
    "1. **Probabilistic Treatment Selection Based on CATE**:\n",
    "   - We use Thompson sampling to select treatments probabilistically based on the CATE estimates and their uncertainties.\n",
    "\n",
    "   For each age group, we sample from the distributions defined by the models' estimates.\n",
    "\n",
    "   **Example of one iteration for each model:**\n",
    "\n",
    "   - **Model 1**:\n",
    "     - **Young Group**: Samples 4.2 for A and 3.8 for B — chooses A.\n",
    "     - **Old Group**: Samples 5.1 for A and 3.7 for B — chooses A.\n",
    "\n",
    "   - **Model 2**:\n",
    "     - **Young Group**: Samples 3.5 for A and 4.5 for B — chooses B.\n",
    "     - **Old Group**: Samples 4.6 for A and 5.2 for B — chooses B.\n",
    "\n",
    "2. **Simulate the Selection Process**:\n",
    "   - Perform this sampling many times to simulate different scenarios.\n",
    "   - Calculate how often each treatment is chosen in each age group.\n",
    "\n",
    "3. **Calculate ERUPT Scores**:\n",
    "   - For each model, after many iterations, calculate the average outcome for the treatments chosen based on the probabilistic CATE estimates.\n",
    "\n",
    "   Historical outcomes based on the table:\n",
    "\n",
    "   - **Young Group**: Average outcomes for A: 4, for B: 2.\n",
    "   - **Old Group**: Average outcomes for A: 6, for B: 4.5.\n",
    "\n",
    "   **Calculated over many iterations:**\n",
    "\n",
    "   - **Model 1**: \n",
    "     - Young Group: More often chooses A.\n",
    "     - Old Group: More often chooses A.\n",
    "     - Average outcome = $(0.7 * 4 + 0.3 * 2)_{Young} + (0.8 * 6 + 0.2 * 4.5)_{Old}$\n",
    "     - $= (0.7 * 4 + 0.3 * 2) + (0.8 * 6 + 0.2 * 4.5)$\n",
    "     - $= (2.8 + 0.6) + (4.8 + 0.9) = 3.4 + 5.7 = 9.$\n",
    "\n",
    "   - **Model 2**: \n",
    "     - Young Group: More often chooses B.\n",
    "     - Old Group: More often chooses B.\n",
    "     - Average outcome = $(0.4 * 4 + 0.6 * 2)_{Young} + (0.4 * 6 + 0.6 * 4.5)_{Old}$\n",
    "     - $= (0.4 * 4 + 0.6 * 2) + (0.4 * 6 + 0.6 * 4.5)$\n",
    "     - $= (1.6 + 1.2) + (2.4 + 2.7) = 2.8 + 5.1 = 7.9$\n",
    "\n",
    "4. **Compare Models**:\n",
    "   - Compare these average outcomes. The model with the higher average outcome is considered better at using CATE for treatment selection.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In this example, **Model 1** appears to perform better in utilizing CATE to probabilistically select more effective treatments, based on the outcomes in each segment. This approach shows how probabilistic ERUPT can be a powerful tool for comparing models in terms of their ability to use CATE estimates effectively under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suitable Estimators (Provide unertainty naturally)\n",
    "\n",
    "Naturally:\n",
    "- Causal Forest DML: Provides uncertainties naturally from the forest structure.\n",
    "- DR Ortho Forest: Provides standard errors naturally.\n",
    "- DML Ortho Forest: Also provides standard errors naturally.\n",
    "\n",
    "\n",
    "With conditions:\n",
    "- T-Learner: If the underlying models provide standard deviations.\n",
    "- X-Learner: If the second-stage models provide standard deviations.\n",
    "- Forest DR Learner: Can provide standard deviations through the variability of forest predictions.\n",
    "- Linear DR Learner: Can provide standard errors for predictions.\n",
    "- Sparse Linear DR Learner: Can provide uncertainties through methods like bootstrapping.\n",
    "- Linear DML: Provides standard errors if the outcome model is linear.\n",
    "- Sparse Linear DML: Similar to Linear DML with potential bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import math\n",
    "from typing import Optional, Dict, Union, Any, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter  # noqa F401\n",
    "from dowhy.causal_estimator import CausalEstimate\n",
    "from dowhy import CausalModel\n",
    "\n",
    "\n",
    "from causaltune.thirdparty.causalml import metrics\n",
    "from causaltune.erupt import ERUPT\n",
    "from causaltune.utils import treatment_values, psw_joint_weights\n",
    "\n",
    "import dcor\n",
    "\n",
    "\n",
    "class DummyEstimator:\n",
    "    def __init__(\n",
    "        self, cate_estimate: np.ndarray, effect_intervals: Optional[np.ndarray] = None\n",
    "    ):\n",
    "        self.cate_estimate = cate_estimate\n",
    "        self.effect_intervals = effect_intervals\n",
    "\n",
    "    def const_marginal_effect(self, X):\n",
    "        return self.cate_estimate\n",
    "\n",
    "\n",
    "def supported_metrics(problem: str, multivalue: bool, scores_only: bool) -> List[str]:\n",
    "    if problem == \"iv\":\n",
    "        metrics = [\"energy_distance\"]\n",
    "        if not scores_only:\n",
    "            metrics.append(\"ate\")\n",
    "        return metrics\n",
    "    elif problem == \"backdoor\":\n",
    "        print(\"backdoor\")\n",
    "        if multivalue:\n",
    "            # TODO: support other metrics for the multivalue case\n",
    "            return [\"energy_distance\", \"psw_energy_distance\"]\n",
    "        else:\n",
    "            metrics = [\n",
    "                \"erupt\",\n",
    "                \"norm_erupt\",\n",
    "                \"prob_erupt\",\n",
    "                \"qini\",\n",
    "                \"auc\",\n",
    "                # \"r_scorer\",\n",
    "                \"energy_distance\",\n",
    "                \"psw_energy_distance\",\n",
    "            ]\n",
    "            if not scores_only:\n",
    "                metrics.append(\"ate\")\n",
    "            return metrics\n",
    "\n",
    "\n",
    "class Scorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        causal_model: CausalModel,\n",
    "        propensity_model: Any,\n",
    "        problem: str,\n",
    "        multivalue: bool,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Contains scoring logic for CausalTune.\n",
    "\n",
    "        Access methods and attributes via `CausalTune.scorer`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.problem = problem\n",
    "        self.multivalue = multivalue\n",
    "        self.causal_model = copy.deepcopy(causal_model)\n",
    "\n",
    "        self.identified_estimand = causal_model.identify_effect(\n",
    "            proceed_when_unidentifiable=True\n",
    "        )\n",
    "\n",
    "        if problem == \"backdoor\":\n",
    "            print(\n",
    "                \"Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\"\n",
    "            )\n",
    "            treatment_series = causal_model._data[causal_model._treatment[0]]\n",
    "            # this will also fit self.propensity_model, which we'll also use in self.erupt\n",
    "            self.psw_estimator = self.causal_model.estimate_effect(\n",
    "                self.identified_estimand,\n",
    "                method_name=\"backdoor.causaltune.models.MultivaluePSW\",\n",
    "                control_value=0,\n",
    "                treatment_value=treatment_values(treatment_series, 0),\n",
    "                target_units=\"ate\",  # condition used for CATE\n",
    "                confidence_intervals=False,\n",
    "                method_params={\n",
    "                    \"init_params\": {\"propensity_model\": propensity_model},\n",
    "                },\n",
    "            ).estimator\n",
    "\n",
    "            treatment_name = self.psw_estimator._treatment_name\n",
    "            if not isinstance(treatment_name, str):\n",
    "                treatment_name = treatment_name[0]\n",
    "\n",
    "            # No need to call self.erupt.fit() as propensity model is already fitted\n",
    "            # self.propensity_model = est.propensity_model\n",
    "            self.erupt = ERUPT(\n",
    "                treatment_name=treatment_name,\n",
    "                propensity_model=self.psw_estimator.estimator.propensity_model,\n",
    "                X_names=self.psw_estimator._effect_modifier_names\n",
    "                + self.psw_estimator._observed_common_causes_names,\n",
    "            )\n",
    "\n",
    "    def ate(self, df: pd.DataFrame) -> tuple:\n",
    "        \"\"\"Calculate the Average Treatment Effect. Provide naive std estimates in single-treatment cases.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "\n",
    "        Returns:\n",
    "            tuple: tuple containing the ATE, standard deviation of the estimate (or None if multi-treatment),\n",
    "                and sample size (or None if estimate has more than one dimension)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        estimate = self.psw_estimator.estimator.effect(df).mean(axis=0)\n",
    "\n",
    "        if len(estimate) == 1:\n",
    "            # for now, let's cheat on the std estimation, take that from the naive ate\n",
    "            treatment_name = self.causal_model._treatment[0]\n",
    "            outcome_name = self.causal_model._outcome[0]\n",
    "            naive_est = Scorer.naive_ate(df[treatment_name], df[outcome_name])\n",
    "            return estimate[0], naive_est[1], naive_est[2]\n",
    "        else:\n",
    "            return estimate, None, None\n",
    "\n",
    "    def resolve_metric(self, metric: str) -> str:\n",
    "        \"\"\"Check if supplied metric is supported. If not, default to 'energy_distance'.\n",
    "\n",
    "        Args:\n",
    "            metric (str): evaluation metric\n",
    "\n",
    "        Returns:\n",
    "            str: metric/'energy_distance'\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        metrics = supported_metrics(self.problem, self.multivalue, scores_only=True)\n",
    "\n",
    "        if metric not in metrics:\n",
    "            logging.warning(\n",
    "                f\"Using energy_distance metric as {metric} is not in the list \"\n",
    "                f\"of supported metrics for this usecase ({str(metrics)})\"\n",
    "            )\n",
    "            return \"energy_distance\"\n",
    "        else:\n",
    "            return metric\n",
    "\n",
    "    def resolve_reported_metrics(\n",
    "        self, metrics_to_report: Union[List[str], None], scoring_metric: str\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Check if supplied reporting metrics are valid.\n",
    "\n",
    "        Args:\n",
    "            metrics_to_report (Union[List[str], None]): list of strings specifying the evaluation metrics to compute.\n",
    "                Possible options include 'ate', 'erupt', 'norm_erupt', 'qini', 'auc',\n",
    "                'energy_distance' and 'psw_energy_distance'.\n",
    "            scoring_metric (str): specified metric\n",
    "\n",
    "        Returns:\n",
    "            List[str]: list of valid metrics\n",
    "        \"\"\"\n",
    "\n",
    "        metrics = supported_metrics(self.problem, self.multivalue, scores_only=False)\n",
    "        if metrics_to_report is None:\n",
    "            return metrics\n",
    "        else:\n",
    "            metrics_to_report = sorted(list(set(metrics_to_report + [scoring_metric])))\n",
    "            for m in metrics_to_report.copy():\n",
    "                if m not in metrics:\n",
    "                    logging.warning(\n",
    "                        f\"Dropping the metric {m} for problem: {self.problem} \\\n",
    "                        : must be one of {metrics}\"\n",
    "                    )\n",
    "                    metrics_to_report.remove(m)\n",
    "        return metrics_to_report\n",
    "\n",
    "    @staticmethod\n",
    "    def energy_distance_score(\n",
    "        estimate: CausalEstimate,\n",
    "        df: pd.DataFrame,\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate energy distance score between treated and controls.\n",
    "        For theoretical details, see Ramos-Carreño and Torrecilla (2023).\n",
    "\n",
    "        Args:\n",
    "            estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "\n",
    "        Returns:\n",
    "            float: energy distance score\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Y0X, _, split_test_by = Scorer._Y0_X_potential_outcomes(estimate, df)\n",
    "\n",
    "        YX_1 = Y0X[Y0X[split_test_by] == 1]\n",
    "        YX_0 = Y0X[Y0X[split_test_by] == 0]\n",
    "        select_cols = estimate.estimator._effect_modifier_names + [\"yhat\"]\n",
    "\n",
    "        energy_distance_score = dcor.energy_distance(\n",
    "            YX_1[select_cols], YX_0[select_cols]\n",
    "        )\n",
    "\n",
    "        return energy_distance_score\n",
    "\n",
    "    @staticmethod\n",
    "    def _Y0_X_potential_outcomes(estimate: CausalEstimate, df: pd.DataFrame):\n",
    "        est = estimate.estimator\n",
    "        # assert est.identifier_method in [\"iv\", \"backdoor\"]\n",
    "        treatment_name = (\n",
    "            est._treatment_name\n",
    "            if isinstance(est._treatment_name, str)\n",
    "            else est._treatment_name[0]\n",
    "        )\n",
    "        df[\"dy\"] = estimate.estimator.effect_tt(df)\n",
    "        df[\"yhat\"] = df[est._outcome_name] - df[\"dy\"]\n",
    "\n",
    "        split_test_by = (\n",
    "            est.estimating_instrument_names[0]\n",
    "            if est.identifier_method == \"iv\"\n",
    "            else treatment_name\n",
    "        )\n",
    "\n",
    "        Y0X = copy.deepcopy(df)\n",
    "        return Y0X, treatment_name, split_test_by\n",
    "\n",
    "    def psw_energy_distance(\n",
    "        self,\n",
    "        estimate: CausalEstimate,\n",
    "        df: pd.DataFrame,\n",
    "        normalise_features=False,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate propensity score adjusted energy distance score between treated and controls.\n",
    "\n",
    "        Features are normalised using the sklearn.preprocessing.QuantileTransformer\n",
    "\n",
    "        For theoretical details, see Ramos-Carreño and Torrecilla (2023).\n",
    "\n",
    "        @param estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "        @param df (pandas.DataFrame): input dataframe\n",
    "        @param normalise_features (bool): whether to normalise features with QuantileTransformer\n",
    "\n",
    "        @return float: propensity-score weighted energy distance score\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Y0X, treatment_name, split_test_by = Scorer._Y0_X_potential_outcomes(\n",
    "            estimate, df\n",
    "        )\n",
    "\n",
    "        Y0X_1 = Y0X[Y0X[split_test_by] == 1]\n",
    "        Y0X_0 = Y0X[Y0X[split_test_by] == 0]\n",
    "\n",
    "        YX_1_all_psw = self.psw_estimator.estimator.propensity_model.predict_proba(\n",
    "            Y0X_1[\n",
    "                self.causal_model.get_effect_modifiers()\n",
    "                + self.causal_model.get_common_causes()\n",
    "            ]\n",
    "        )\n",
    "        treatment_series = Y0X_1[treatment_name]\n",
    "\n",
    "        YX_1_psw = np.zeros(YX_1_all_psw.shape[0])\n",
    "        for i in treatment_series.unique():\n",
    "            YX_1_psw[treatment_series == i] = YX_1_all_psw[:, i][treatment_series == i]\n",
    "\n",
    "        YX_0_psw = self.psw_estimator.estimator.propensity_model.predict_proba(\n",
    "            Y0X_0[\n",
    "                self.causal_model.get_effect_modifiers()\n",
    "                + self.causal_model.get_common_causes()\n",
    "            ]\n",
    "        )[:, 0]\n",
    "\n",
    "        select_cols = estimate.estimator._effect_modifier_names + [\"yhat\"]\n",
    "        features = estimate.estimator._effect_modifier_names\n",
    "\n",
    "        xy_psw = psw_joint_weights(YX_1_psw, YX_0_psw)\n",
    "        xx_psw = psw_joint_weights(YX_0_psw)\n",
    "        yy_psw = psw_joint_weights(YX_1_psw)\n",
    "\n",
    "        xy_mean_weights = np.mean(xy_psw)\n",
    "        xx_mean_weights = np.mean(xx_psw)\n",
    "        yy_mean_weights = np.mean(yy_psw)\n",
    "\n",
    "        if normalise_features:\n",
    "            qt = QuantileTransformer(n_quantiles=200)\n",
    "            X_quantiles = qt.fit_transform(Y0X[features])\n",
    "\n",
    "            Y0X_transformed = pd.DataFrame(\n",
    "                X_quantiles, columns=features, index=Y0X.index\n",
    "            )\n",
    "            Y0X_transformed.loc[:, [\"yhat\", split_test_by]] = Y0X[\n",
    "                [\"yhat\", split_test_by]\n",
    "            ]\n",
    "\n",
    "            Y0X_1 = Y0X_transformed[Y0X_transformed[split_test_by] == 1]\n",
    "            Y0X_0 = Y0X_transformed[Y0X_transformed[split_test_by] == 0]\n",
    "\n",
    "        exponent = 1\n",
    "        distance_xy = np.reciprocal(xy_mean_weights) * np.multiply(\n",
    "            xy_psw,\n",
    "            dcor.distances.pairwise_distances(\n",
    "                Y0X_1[select_cols], Y0X_0[select_cols], exponent=exponent\n",
    "            ),\n",
    "        )\n",
    "        distance_yy = np.reciprocal(yy_mean_weights) * np.multiply(\n",
    "            yy_psw,\n",
    "            dcor.distances.pairwise_distances(Y0X_1[select_cols], exponent=exponent),\n",
    "        )\n",
    "        distance_xx = np.reciprocal(xx_mean_weights) * np.multiply(\n",
    "            xx_psw,\n",
    "            dcor.distances.pairwise_distances(Y0X_0[select_cols], exponent=exponent),\n",
    "        )\n",
    "        psw_energy_distance = (\n",
    "            2 * np.mean(distance_xy) - np.mean(distance_xx) - np.mean(distance_yy)\n",
    "        )\n",
    "        return psw_energy_distance\n",
    "\n",
    "    @staticmethod\n",
    "    def qini_make_score(\n",
    "        estimate: CausalEstimate, df: pd.DataFrame, cate_estimate: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate the Qini score, defined as the area between the Qini curves of a model and random.\n",
    "\n",
    "        Args:\n",
    "            estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "            cate_estimate (np.ndarray): array with cate estimates\n",
    "\n",
    "        Returns:\n",
    "            float: Qini score\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        est = estimate.estimator\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"y\"] = df[est._outcome_name]\n",
    "        treatment_name = est._treatment_name\n",
    "        if not isinstance(treatment_name, str):\n",
    "            treatment_name = treatment_name[0]\n",
    "        new_df[\"w\"] = df[treatment_name]\n",
    "        new_df[\"model\"] = cate_estimate\n",
    "\n",
    "        qini_score = metrics.qini_score(new_df)\n",
    "\n",
    "        return qini_score[\"model\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def auc_make_score(\n",
    "        estimate: CausalEstimate, df: pd.DataFrame, cate_estimate: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate the area under the uplift curve.\n",
    "\n",
    "        Args:\n",
    "            estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "            cate_estimate (np.ndarray): array with cate estimates\n",
    "\n",
    "        Returns:\n",
    "            float: area under the uplift curve\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        est = estimate.estimator\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"y\"] = df[est._outcome_name]\n",
    "        treatment_name = est._treatment_name\n",
    "        if not isinstance(treatment_name, str):\n",
    "            treatment_name = treatment_name[0]\n",
    "        new_df[\"w\"] = df[treatment_name]\n",
    "        new_df[\"model\"] = cate_estimate\n",
    "\n",
    "        auc_score = metrics.auuc_score(new_df)\n",
    "\n",
    "        return auc_score[\"model\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def real_qini_make_score(\n",
    "        estimate: CausalEstimate, df: pd.DataFrame, cate_estimate: np.ndarray\n",
    "    ) -> float:\n",
    "        # TODO  To calculate the 'real' qini score for synthetic datasets, to be done\n",
    "\n",
    "        # est = estimate.estimator\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        # new_df['tau'] = [df['y_factual'] - df['y_cfactual']]\n",
    "        new_df[\"model\"] = cate_estimate\n",
    "\n",
    "        qini_score = metrics.qini_score(new_df)\n",
    "\n",
    "        return qini_score[\"model\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def r_make_score(\n",
    "        estimate: CausalEstimate, df: pd.DataFrame, cate_estimate: np.ndarray, r_scorer\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate r_score.\n",
    "        For details refer to Nie and Wager (2017) and Schuler et al. (2018). Adaption from EconML implementation.\n",
    "\n",
    "        Args:\n",
    "            estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "            cate_estimate (np.ndarray): array with cate estimates\n",
    "            r_scorer: callable object used to compute the R-score\n",
    "\n",
    "        Returns:\n",
    "            float: r_score\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        return r_scorer.score(cate_estimate)\n",
    "\n",
    "    @staticmethod\n",
    "    def naive_ate(treatment: pd.Series, outcome: pd.Series):\n",
    "        \"\"\"Calculate simple ATE.\n",
    "\n",
    "        Args:\n",
    "            treatment (pandas.Series): series of treatments\n",
    "            outcome (pandas.Series): series of outcomes\n",
    "\n",
    "        Returns:\n",
    "            tuple: tuple of simple ATE, standard deviation, and sample size\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        treated = (treatment == 1).sum()\n",
    "\n",
    "        mean_ = outcome[treatment == 1].mean() - outcome[treatment == 0].mean()\n",
    "        std1 = outcome[treatment == 1].std() / (math.sqrt(treated) + 1e-3)\n",
    "        std2 = outcome[treatment == 0].std() / (\n",
    "            math.sqrt(len(outcome) - treated) + 1e-3\n",
    "        )\n",
    "        std_ = math.sqrt(std1 * std1 + std2 * std2)\n",
    "        return (mean_, std_, len(treatment))\n",
    "\n",
    "    def group_ate(\n",
    "        self, df: pd.DataFrame, policy: Union[pd.DataFrame, np.ndarray]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Compute the average treatment effect (ATE) for different groups specified by a policy.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): input dataframe, should contain columns for the treatment, outcome, and policy\n",
    "            policy (Union[pd.DataFrame, np.ndarray]): policy column in df or an array of the policy values,\n",
    "                used to group the data\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: ATE, std, and size per policy\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        tmp = {\"all\": self.ate(df)}\n",
    "        for p in sorted(list(policy.unique())):\n",
    "            tmp[p] = self.ate(df[policy == p])\n",
    "\n",
    "        tmp2 = [\n",
    "            {\"policy\": str(p), \"mean\": m, \"std\": s, \"count\": c}\n",
    "            for p, (m, s, c) in tmp.items()\n",
    "        ]\n",
    "\n",
    "        return pd.DataFrame(tmp2)\n",
    "\n",
    "    def make_scores(\n",
    "        self,\n",
    "        estimate: CausalEstimate,\n",
    "        df: pd.DataFrame,\n",
    "        metrics_to_report: List[str],\n",
    "        r_scorer=None,\n",
    "    ) -> dict:\n",
    "        \"\"\"Calculate various performance metrics for a given causal estimate using a given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            estimate (dowhy.causal_estimator.CausalEstimate): causal estimate to evaluate\n",
    "            df (pandas.DataFrame): input dataframe\n",
    "            metrics_to_report (List[str]): list of strings specifying the evaluation metrics to compute.\n",
    "                Possible options include 'ate', 'erupt', 'norm_erupt', 'qini', 'auc',\n",
    "                'energy_distance' and 'psw_energy_distance'.\n",
    "            r_scorer (Optional): callable object used to compute the R-score, default is None\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary containing the evaluation metrics specified in metrics_to_report.\n",
    "                The values key in the dictionary contains the input DataFrame with additional columns for\n",
    "                the propensity scores, the policy, the normalized policy, and the weights, if applicable.\n",
    "        \"\"\"\n",
    "\n",
    "        out = dict()\n",
    "        df = df.copy().reset_index()\n",
    "\n",
    "        est = estimate.estimator\n",
    "        treatment_name = est._treatment_name\n",
    "        if not isinstance(treatment_name, str):\n",
    "            treatment_name = treatment_name[0]\n",
    "        outcome_name = est._outcome_name\n",
    "\n",
    "        cate_estimate = est.effect(df)\n",
    "\n",
    "        # TODO: fix this hack with proper treatment of multivalues\n",
    "        if len(cate_estimate.shape) > 1 and cate_estimate.shape[1] == 1:\n",
    "            cate_estimate = cate_estimate.reshape(-1)\n",
    "\n",
    "        # TODO: fix this, currently broken\n",
    "        # covariates = est._effect_modifier_names\n",
    "        # Include CATE Interpereter for both IV and CATE models\n",
    "        # intrp = SingleTreeCateInterpreter(\n",
    "        #     include_model_uncertainty=False, max_depth=2, min_samples_leaf=10\n",
    "        # )\n",
    "        # intrp.interpret(DummyEstimator(cate_estimate), df[covariates])\n",
    "        # intrp.feature_names = covariates\n",
    "        # out[\"intrp\"] = intrp\n",
    "\n",
    "        if self.problem == \"backdoor\":\n",
    "            values = df[[treatment_name, outcome_name]]\n",
    "            simple_ate = self.ate(df)[0]\n",
    "            if isinstance(simple_ate, float):\n",
    "                # simple_ate = simple_ate[0]\n",
    "                # .reset_index(drop=True)\n",
    "                values[\n",
    "                    \"p\"\n",
    "                ] = self.psw_estimator.estimator.propensity_model.predict_proba(\n",
    "                    df[\n",
    "                        self.causal_model.get_effect_modifiers()\n",
    "                        + self.causal_model.get_common_causes()\n",
    "                    ]\n",
    "                )[\n",
    "                    :, 1\n",
    "                ]\n",
    "                values[\"policy\"] = cate_estimate > 0\n",
    "                values[\"norm_policy\"] = cate_estimate > simple_ate\n",
    "                values[\"weights\"] = self.erupt.weights(df, lambda x: cate_estimate > 0)\n",
    "            else:\n",
    "                pass\n",
    "                # TODO: what do we do here if multiple treatments?\n",
    "\n",
    "            if \"erupt\" in metrics_to_report:\n",
    "                erupt_score = self.erupt.score(df, df[outcome_name], cate_estimate > 0)\n",
    "                out[\"erupt\"] = erupt_score\n",
    "\n",
    "            if \"norm_erupt\" in metrics_to_report:\n",
    "                norm_erupt_score = (\n",
    "                    self.erupt.score(df, df[outcome_name], cate_estimate > simple_ate)\n",
    "                    - simple_ate * values[\"norm_policy\"].mean()\n",
    "                )\n",
    "                out[\"norm_erupt\"] = norm_erupt_score\n",
    "\n",
    "            if \"prob_erupt\" in metrics_to_report:\n",
    "                treatment_effects = pd.Series(cate_estimate, index=df.index)\n",
    "                treatment_std_devs = pd.Series(cate_estimate.std(), index=df.index)\n",
    "                prob_erupt_score = self.erupt.probabilistic_erupt_score(df, df[outcome_name], treatment_effects, treatment_std_devs)\n",
    "                out[\"prob_erupt\"] = prob_erupt_score\n",
    "\n",
    "            if \"qini\" in metrics_to_report:\n",
    "                out[\"qini\"] = Scorer.qini_make_score(estimate, df, cate_estimate)\n",
    "\n",
    "            if \"auc\" in metrics_to_report:\n",
    "                out[\"auc\"] = Scorer.auc_make_score(estimate, df, cate_estimate)\n",
    "\n",
    "            if r_scorer is not None:\n",
    "                out[\"r_score\"] = Scorer.r_make_score(\n",
    "                    estimate, df, cate_estimate, r_scorer\n",
    "                )\n",
    "\n",
    "            # values = values.rename(columns={treatment_name: \"treated\"})\n",
    "            assert len(values) == len(df), \"Index weirdness when adding columns!\"\n",
    "            values = values.copy()\n",
    "            out[\"values\"] = values\n",
    "\n",
    "        if \"ate\" in metrics_to_report:\n",
    "            out[\"ate\"] = cate_estimate.mean()\n",
    "            out[\"ate_std\"] = cate_estimate.std()\n",
    "\n",
    "        if \"energy_distance\" in metrics_to_report:\n",
    "            out[\"energy_distance\"] = Scorer.energy_distance_score(estimate, df)\n",
    "\n",
    "        if \"psw_energy_distance\" in metrics_to_report:\n",
    "            out[\"psw_energy_distance\"] = self.psw_energy_distance(\n",
    "                estimate,\n",
    "                df,\n",
    "            )\n",
    "\n",
    "        del df\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def best_score_by_estimator(\n",
    "        scores: Dict[str, dict], metric: str\n",
    "    ) -> Dict[str, dict]:\n",
    "        \"\"\"Obtain best score for each estimator.\n",
    "\n",
    "        Args:\n",
    "            scores (Dict[str, dict]): CausalTune.scores dictionary\n",
    "            metric (str): metric of interest\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, dict]: dictionary containing best score by estimator\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for k, v in scores.items():\n",
    "            if \"estimator_name\" not in v:\n",
    "                raise ValueError(\n",
    "                    f\"Malformed scores dict, 'estimator_name' field missing in {k}, {v}\"\n",
    "                )\n",
    "\n",
    "        estimator_names = sorted(\n",
    "            list(\n",
    "                set(\n",
    "                    [\n",
    "                        v[\"estimator_name\"]\n",
    "                        for v in scores.values()\n",
    "                        if \"estimator_name\" in v\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        best = {}\n",
    "        for name in estimator_names:\n",
    "            est_scores = [\n",
    "                v\n",
    "                for v in scores.values()\n",
    "                if \"estimator_name\" in v and v[\"estimator_name\"] == name\n",
    "            ]\n",
    "            best[name] = (\n",
    "                min(est_scores, key=lambda x: x[metric])\n",
    "                if metric in [\"energy_distance\", \"psw_energy_distance\"]\n",
    "                else max(est_scores, key=lambda x: x[metric])\n",
    "            )\n",
    "\n",
    "        return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Union\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable, List, Optional, Union\n",
    "\n",
    "# implementation of https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957\n",
    "# we assume treatment takes integer values from 0 to n\n",
    "\n",
    "\n",
    "class DummyPropensity:\n",
    "    def __init__(self, p: pd.Series, treatment: pd.Series):\n",
    "        n_vals = max(treatment) + 1\n",
    "        out = np.zeros((len(treatment), n_vals))\n",
    "        for i, pp in enumerate(p.values):\n",
    "            out[i, treatment.values[i]] = pp\n",
    "        self.p = out\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self):\n",
    "        return self.p\n",
    "\n",
    "\n",
    "class ERUPT:\n",
    "    def __init__(\n",
    "        self,\n",
    "        treatment_name: str,\n",
    "        propensity_model,\n",
    "        X_names: Optional[List[str]] = None,\n",
    "        clip: float = 0.05,\n",
    "        remove_tiny: bool = True,\n",
    "    ):\n",
    "        self.treatment_name = treatment_name\n",
    "        self.propensity_model = copy.deepcopy(propensity_model)\n",
    "        self.X_names = X_names\n",
    "        self.clip = clip\n",
    "        self.remove_tiny = remove_tiny\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        if self.X_names is None:\n",
    "            self.X_names = [c for c in df.columns if c != self.treatment_name]\n",
    "        self.propensity_model.fit(df[self.X_names], df[self.treatment_name])\n",
    "\n",
    "    def score(\n",
    "        self, df: pd.DataFrame, outcome: pd.Series, policy: Callable\n",
    "    ) -> pd.Series:\n",
    "        w = self.weights(df, policy)\n",
    "        return (w * outcome).mean()\n",
    "\n",
    "    def weights(\n",
    "        self, df: pd.DataFrame, policy: Union[Callable, np.ndarray, pd.Series]\n",
    "    ) -> pd.Series:\n",
    "        W = df[self.treatment_name].astype(int)\n",
    "        assert all(\n",
    "            [x >= 0 for x in W.unique()]\n",
    "        ), \"Treatment values must be non-negative integers\"\n",
    "\n",
    "        if callable(policy):\n",
    "            policy = policy(df).astype(int)\n",
    "        if isinstance(policy, pd.Series):\n",
    "            policy = policy.values\n",
    "        policy = np.array(policy)\n",
    "\n",
    "        d = pd.Series(index=df.index, data=policy)\n",
    "        assert all(\n",
    "            [x >= 0 for x in d.unique()]\n",
    "        ), \"Policy values must be non-negative integers\"\n",
    "\n",
    "        if isinstance(self.propensity_model, DummyPropensity):\n",
    "            p = self.propensity_model.predict_proba()\n",
    "        else:\n",
    "            p = self.propensity_model.predict_proba(df[self.X_names])\n",
    "        p = np.maximum(p, 1e-4)\n",
    "\n",
    "        weight = np.zeros(len(df))\n",
    "\n",
    "        for i in W.unique():\n",
    "            weight[W == i] = 1 / p[:, i][W == i]\n",
    "\n",
    "        weight[d != W] = 0.0\n",
    "\n",
    "        if self.remove_tiny:\n",
    "            weight[weight > 1 / self.clip] = 0.0\n",
    "        else:\n",
    "            weight[weight > 1 / self.clip] = 1 / self.clip\n",
    "\n",
    "        weight *= len(df) / sum(weight)\n",
    "        assert not np.isnan(weight.sum()), \"NaNs in ERUPT weights\"\n",
    "\n",
    "        return pd.Series(index=df.index, data=weight)\n",
    "\n",
    "    def probabilistic_erupt_score(\n",
    "        self, df: pd.DataFrame, outcome: pd.Series, treatment_effects: pd.Series, treatment_std_devs: pd.Series, iterations: int = 1000\n",
    "    ) -> float:\n",
    "        unique_treatments = df[self.treatment_name].unique()\n",
    "        treatment_scores = {treatment: [] for treatment in unique_treatments}\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            sampled_effects = {\n",
    "                treatment: np.random.normal(treatment_effects.loc[treatment], treatment_std_devs.loc[treatment])\n",
    "                for treatment in unique_treatments\n",
    "            }\n",
    "            chosen_treatment = max(sampled_effects, key=sampled_effects.get)\n",
    "            # Compute weighted outcome\n",
    "            weights = self.weights(df, lambda x: np.array([chosen_treatment] * len(x)))\n",
    "            mean_outcome = (weights * outcome).sum() / weights.sum()\n",
    "            treatment_scores[chosen_treatment].append(mean_outcome)\n",
    "\n",
    "        average_outcomes = np.mean([np.mean(scores) for scores in treatment_scores.values() if scores])\n",
    "\n",
    "        return average_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Groups with Questions\n",
    "\n",
    "## (Ridge / LASSO) Regression\n",
    "\n",
    "3. (2019) Consider the multiple linear regression model without the intercept term,\n",
    "\n",
    "$$\n",
    "\\mathbf{Y}=\\mathbf{X} \\boldsymbol{\\beta}+\\boldsymbol{\\varepsilon}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{Y}=\\left(Y_{1}, \\ldots, Y_{n}\\right)^{T}, \\boldsymbol{\\beta}=\\left(\\beta_{1}, \\ldots, \\beta_{p}\\right)^{T}, \\boldsymbol{\\varepsilon}=\\left(\\varepsilon_{1}, \\ldots, \\varepsilon_{n}\\right)^{T} \\sim N\\left(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n}\\right)$ and $\\mathbf{X}=$ $\\left(\\mathbf{v}_{1}, \\ldots, \\mathbf{v}_{p}\\right) \\in \\mathbb{R}^{n \\times p}$ is the design matrix with $\\mathbf{v}_{j}=\\left(X_{1 j}, \\ldots, X_{n j}\\right)^{T}$. The ridge regression estimator solves the following minimisation problem,\n",
    "\n",
    "$$\n",
    "\\min _{\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}}\\|\\mathbf{Y}-\\mathbf{X} \\boldsymbol{\\beta}\\|^{2}+\\lambda \\sum_{j=1}^{p} \\beta_{j}^{2}\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is a non-negative tuning parameter. In class, we have shown that the solution is given by\n",
    "\n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\beta}}_{\\text {ridge }}=\\left(\\mathbf{X}^{T} \\mathbf{X}+\\lambda \\mathbf{I}_{p}\\right)^{-1} \\mathbf{X}^{T} \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "Suppose that the columns of $\\mathbf{X}$ are mutually orthogonal.\n",
    "\n",
    "(a) Show that $\\widehat{\\boldsymbol{\\beta}}_{\\text {ridge }}$ can be found element by element by solving $p$ separate ridge regression problems as follows,\n",
    "\n",
    "$$\n",
    "\\min _{\\beta_{j} \\in \\mathbb{R}}\\left\\|\\mathbf{Y}-\\mathbf{v}_{j} \\beta_{j}\\right\\|^{2}+\\lambda \\beta_{j}^{2}, j=1, \\ldots, p\n",
    "$$\n",
    "\n",
    "(b) Show that the sum of squares explained by the full ridge regression is the sum of those explained in each of the $p$ separate ridge regressions, that is\n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{X} \\widehat{\\boldsymbol{\\beta}}_{\\text {ridge }}\\right)^{T}\\left(\\mathbf{X} \\widehat{\\boldsymbol{\\beta}}_{\\text {ridge }}\\right)=\\sum_{j=1}^{p}\\left(\\mathbf{v}_{j} \\widehat{\\beta}_{\\text {ridge }, \\mathrm{j}}\\right)^{T}\\left(\\mathbf{v}_{j} \\widehat{\\beta}_{\\text {ridge }, \\mathrm{j}}\\right)\n",
    "$$\n",
    "\n",
    "where $\\widehat{\\beta}_{\\text {ridge }, j}$ is the $j$-th component of $\\widehat{\\boldsymbol{\\beta}}_{\\text {ridge }}$ for $j=1, \\ldots, p$.\n",
    "\n",
    "[10 marks]\n",
    "\n",
    "(c) Let $\\mathbf{v}_{1}^{T} \\mathbf{v}_{1}=2$. Find the mean square error (MSE) for $\\widehat{\\beta}_{\\text {ridge, }}$. What is the value of $\\lambda$ that minimises $\\operatorname{MSE}\\left(\\widehat{\\beta}_{\\text {ridge }, 1}\\right)$ ?\n",
    "\n",
    "[9 marks]\n",
    "\n",
    "2 (d) (2020) For multiple linear regression model without the intercept term,\n",
    "\n",
    "$$\n",
    "\\mathbf{Y}=\\mathbf{X} \\boldsymbol{\\beta}+\\boldsymbol{\\varepsilon}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{Y}=\\left(Y_{1}, \\ldots, Y_{n}\\right)^{T}, \\boldsymbol{\\beta}=\\left(\\beta_{1}, \\ldots, \\beta_{p}\\right)^{T}, \\boldsymbol{\\varepsilon}=\\left(\\varepsilon_{1}, \\ldots, \\varepsilon_{n}\\right)^{T} \\sim N\\left(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n}\\right)$ and $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$. Consider the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\min _{\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}}\\|\\mathbf{Y}-\\mathbf{X} \\boldsymbol{\\beta}\\|^{2}+\\lambda \\sum_{j=1}^{p}\\left[\\alpha \\beta_{j}^{2}+(1-\\alpha)\\left|\\beta_{j}\\right|\\right]\n",
    "$$\n",
    "\n",
    "where $\\lambda \\geq 0$ and $0 \\leq \\alpha \\leq 1$ are two tuning parameters. Show how one can turn the above optimization problem into an instance of the lasso problem, using augmented versions of $\\mathbf{X}$ and $\\mathbf{Y}$, denoted by $\\widetilde{\\mathbf{X}}$ and $\\widetilde{\\mathbf{Y}}$, respectively. What is the resulting lasso problem in terms of $\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{Y}}$ and the corresponding tuning parameter $\\widetilde{\\lambda}$ ? [7 marks]\n",
    "\n",
    "3. (2021) Consider multiple linear regression without the intercept term. Let $\\boldsymbol{\\beta}=\\left(\\beta_{1}, \\ldots, \\beta_{p}\\right)^{\\mathrm{T}}$ and $\\mathbf{x}_{i}=\\left(x_{i 1}, \\ldots, x_{i p}\\right)^{\\mathrm{T}}$. Suppose that the training data $\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$ satisfy\n",
    "\n",
    "$$\n",
    "y_{i}=\\boldsymbol{\\beta}^{\\mathrm{T}} \\mathbf{x}_{i}+\\varepsilon_{i}, \\quad i=1, \\ldots, n\n",
    "$$\n",
    "\n",
    "and the test data $\\left\\{\\left(\\tilde{\\mathbf{x}}_{i^{\\prime}}, \\tilde{y}_{i^{\\prime}}\\right)\\right\\}_{i^{\\prime}=1}^{m}$ satisfy\n",
    "\n",
    "$$\n",
    "\\tilde{y}_{i^{\\prime}}=\\boldsymbol{\\beta}^{\\mathrm{T}} \\tilde{\\mathbf{x}}_{i^{\\prime}}+\\tilde{\\varepsilon}_{i^{\\prime}}, \\quad i^{\\prime}=1, \\ldots, m\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\mathbf{x}}_{i^{\\prime}}=\\left(\\tilde{x}_{i^{\\prime} 1}, \\ldots, \\tilde{x}_{i^{\\prime} p}\\right)^{\\mathrm{T}}$.\n",
    "\n",
    "(a) An estimator is scale-invariant in the sense that the test set prediction accuracy is unchanged if one rescales $\\mathbf{x}_{i}$ and $\\tilde{\\mathbf{x}}_{i^{\\prime}}$ as $c \\mathbf{x}_{i}$ and $c \\tilde{\\mathbf{x}}_{i^{\\prime}}$, respectively, for all $i, i^{\\prime}$, where $c$ is some nonzero constant. You may use formulas for the least squares and ridge regression estimators of $\\beta$ without proof.\n",
    "\n",
    "i. Justify whether the least squares estimator is scale-invariant or not. [6 marks]\n",
    "\n",
    "ii. Justify whether the ridge regression estimator with a fixed tuning parameter $\\lambda$ is scale-invariant or not.\n",
    "\n",
    "[6 marks]\n",
    "(b) Suppose that $\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$ and $\\left\\{\\left(\\tilde{\\mathbf{x}}_{i^{\\prime}}, \\tilde{y}_{i^{\\prime}}\\right)\\right\\}_{i^{\\prime}=1}^{m}$ are drawn at random from a population. Let $\\hat{\\boldsymbol{\\beta}}$ be the least squares estimator obtained from $\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$. If $R_{\\mathrm{tr}}(\\boldsymbol{\\beta})=$ $\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\boldsymbol{\\beta}^{\\mathrm{T}} \\mathbf{x}_{i}\\right)^{2}$ and $R_{\\mathrm{te}}(\\boldsymbol{\\beta})=\\frac{1}{m} \\sum_{i^{\\prime}=1}^{m}\\left(\\tilde{y}_{i^{\\prime}}-\\boldsymbol{\\beta}^{\\mathrm{T}} \\tilde{\\mathbf{x}}_{i^{\\prime}}\\right)^{2}$, prove that\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[R_{\\mathrm{tr}}(\\hat{\\boldsymbol{\\beta}})\\right] \\leq \\mathbb{E}\\left[R_{\\mathrm{te}}(\\hat{\\boldsymbol{\\beta}})\\right]\n",
    "$$\n",
    "\n",
    "where expectations are over all that is random in each expression.\n",
    "\n",
    "[9 marks]\n",
    "\n",
    "\n",
    "## Tree Based Methods\n",
    "\n",
    "#### Classification Trees\n",
    "4. (2019) This problem is about the construction of classification trees. Each split is typically made in order to minimise the cost function\n",
    "\n",
    "$$\n",
    "C(T)=\\sum_{m=1}^{|T|} N_{m} Q_{m}\n",
    "$$\n",
    "\n",
    "where $T$ is the tree object, $|T|$ is total number of terminal nodes, $N_{m}$ is the number of training data points in the region corresponding to the $m$-th terminal node, and $Q_{m}$ is the node impurity measure of the same region. In class, we have introduced two common measures including \"misclassification error\" and \"Gini index\". Consider a two-class classification problem with two inputs and a training dataset illustrated in Figure 2. There are infinitely many possible splits we could make, but we restrict ourselves to split at integer values in the region where the training data is located.\n",
    "\n",
    "Figure 2: Training dataset with two inputs $X_{1}, X_{2}$ and two classes for $Y$ : \"solid circle\" and \"hollow circle\".\n",
    "\n",
    "(a) Give an optimal classification tree with two split points for minimizing the training misclassification loss.\n",
    "\n",
    "[4 marks]\n",
    "\n",
    "(b) If we use the misclassification error as the node impurity measure, what is the resulting classification tree with two split points obtained by recursive binary splitting? Explain the suboptimality of the solution.\n",
    "\n",
    "[5 marks]\n",
    "\n",
    "(c) Consider the first split point. If we use the Gini index as the node impurity measure, compute the cost $C(T)$ for the following two candidate splits\n",
    "i. $R_{1}=\\left\\{X: X_{1} \\leq 1\\right\\}$ and $R_{2}=\\left\\{X: X_{1}>1\\right\\}$,\n",
    "\n",
    "ii. $R_{1}=\\left\\{X: X_{1} \\leq 2\\right\\}$ and $R_{2}=\\left\\{X: X_{1}>2\\right\\}$.\n",
    "\n",
    "Among the above two candidate splits in i. and ii., where would we make the first split?\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "2. (2021) This problem is on the topic of constructing classification trees. Each split can be made based on the cost function\n",
    "\n",
    "$$\n",
    "C(T)=\\sum_{m=1}^{|T|} N_{m} Q_{m}\n",
    "$$\n",
    "\n",
    "Consider a two-class classification problem with two inputs and a training dataset illustrated in Figure 2. For the first split point, we consider the following three candidate splits:\n",
    "i. $R_{1}=\\left\\{X: X_{1} \\leq 0.25\\right\\}$ and $R_{2}=\\left\\{X: X_{1}>0.25\\right\\}$,\n",
    "\n",
    "ii. $R_{1}=\\left\\{X: X_{1} \\leq 0.5\\right\\}$ and $R_{2}=\\left\\{X: X_{1}>0.5\\right\\}$,\n",
    "\n",
    "iii. $R_{1}=\\left\\{X: X_{1} \\leq 0.75\\right\\}$ and $R_{2}=\\left\\{X: X_{1}>0.75\\right\\}$.\n",
    "\n",
    "(a) If we use misclassification error rate as the node impurity measure $Q_{m}$, compute $C(T)$ for splits in i. and iii. Among two candidate splits in i. and iii., where would we make the split?\n",
    "\n",
    "(b) If we use Gini index as the node impurity measure $Q_{m}$, compute the cost $C(T)$ for splits in ii. and iii. Among two candidate splits in ii. and iii., where would we make the split?\n",
    "\n",
    "[8 marks]\n",
    "\n",
    "\n",
    "Figure 2: Training dataset with $X_{1}, X_{2}$ and two classes for $Y$ : \"red circle\" and \"blue square\".\n",
    "\n",
    "#### Regression Trees\n",
    "5. (2021) Consider $y_{i}=f\\left(\\mathbf{x}_{i}\\right)+\\varepsilon_{i}$ for $i=1, \\ldots, n$, where $\\varepsilon_{i}$ 's are i.i.d. with mean zero and variance $\\sigma^{2}$, and $\\mathbf{x}_{i}=\\left(x_{i 1}, \\ldots, x_{i p}\\right)^{\\mathrm{T}}$. Let $\\mathbf{x}_{i} \\in[0,1]^{p}=[0,1] \\times \\cdots \\times[0,1]$. Divide each $[0,1]$ into intervals with the same length $h>0$. Hence, $[0,1]^{p}$ is divided into $J$ non-overlapping $p$ dimensional regions, $B_{1}, \\ldots, B_{J}$. Treat $\\mathbf{x}_{i}$ 's as fixed. For $\\mathbf{x} \\in[0,1]^{p}$, let\n",
    "\n",
    "$$\n",
    "\\hat{f}(\\mathbf{x})=\\frac{1}{N(\\mathbf{x})} \\sum_{i=1}^{n} y_{i} I\\left(\\mathbf{x}_{i} \\in B(\\mathbf{x})\\right)\n",
    "$$\n",
    "\n",
    "where $B(\\mathbf{x})$ is the $p$-dimensional region containing $\\mathbf{x}$ and $N(\\mathbf{x})=\\sum_{i=1}^{n} I\\left(\\mathbf{x}_{i} \\in B(\\mathbf{x})\\right)$ is the number of $\\mathbf{x}_{i}{ }^{\\prime} \\mathrm{s}$ in $B(\\mathbf{x})$. Further assume that $\\left|f(\\mathbf{x})-f\\left(\\mathbf{x}^{\\prime}\\right)\\right| \\leq L\\left\\|\\mathbf{x}-\\mathbf{x}^{\\prime}\\right\\|=L\\left\\{\\sum_{j=1}^{p}\\left(x_{j}-\\right.\\right.$ $\\left.\\left.x_{j}^{\\prime}\\right)^{2}\\right\\}^{1 / 2}$ for some positive constant $L$ and all $\\mathbf{x}, \\mathbf{x}^{\\prime} \\in[0,1]^{p}$. Prove that\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[(\\hat{f}(\\mathbf{x})-f(\\mathbf{x}))^{2}\\right] \\leq L^{2} p h^{2}+\\frac{\\sigma^{2}}{N(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "(Hint: consider the variance and bias decomposition of the mean squared error.)\n",
    "\n",
    "[13 marks]\n",
    "\n",
    "\n",
    "\n",
    "## Clustering (k-means)\n",
    "\n",
    "5. (2019) Let $\\mathbf{x}_{1}, \\ldots, \\mathbf{x}_{n}$ be a dataset of $p$-dimensional vectors and $\\left\\{C_{1}, \\ldots, C_{K}\\right\\}$ be a partition of $\\{1, \\ldots, n\\}$. Let $n_{k}$ be the number of observations in cluster $C_{k}$ for $k=1, \\ldots, K$. For each cluster $C_{k}$, define $\\overline{\\mathbf{x}}_{k}=\\frac{1}{n_{k}} \\sum_{i \\in C_{k}} \\mathbf{x}_{i}$ to be the within-cluster mean and $\\overline{\\mathbf{x}}=\\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{x}_{i}$ to\n",
    "be the overall mean. Let\n",
    "\n",
    "$\\mathbf{T}=\\sum_{k=1}^{K} \\sum_{i \\in C_{k}}\\left(\\mathbf{x}_{i}-\\overline{\\mathbf{x}}\\right)\\left(\\mathbf{x}_{i}-\\overline{\\mathbf{x}}\\right)^{T}$ to be the total deviance to the overall mean,\n",
    "\n",
    "$\\mathbf{W}=\\sum_{k=1}^{K} \\sum_{i \\in C_{k}}\\left(\\mathbf{x}_{i}-\\overline{\\mathbf{x}}_{k}\\right)\\left(\\mathbf{x}_{i}-\\overline{\\mathbf{x}}_{k}\\right)^{T}$ to be the within-cluster deviance to the cluster mean,\n",
    "\n",
    "$\\mathbf{B}=\\sum_{k=1}^{K} \\sum_{i \\in C_{k}}\\left(\\mathbf{x}_{k}-\\overline{\\mathbf{x}}\\right)\\left(\\mathbf{x}_{k}-\\overline{\\mathbf{x}}\\right)^{T}$ to be the between cluster deviance,\n",
    "\n",
    "where $\\mathbf{T}, \\mathbf{W}$ and $\\mathbf{B} \\in \\mathbb{R}^{p \\times p}$.\n",
    "(a) Verify that $\\mathbf{T}=\\mathbf{W}+\\mathbf{B}$.\n",
    "\n",
    "(b) Explain how the objective function of $K$-means is related to $\\mathbf{W}$.\n",
    "\n",
    "(c) Explain how $\\mathbf{T}$ and $\\mathbf{B}$ change during the course of the $K$-means algorithm.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "5. (2020) Some of the most commonly-used types of linkage in hierarchical clustering are\n",
    "\n",
    "- Single linkage: distance between clusters is the minimum distance between any pair of points from two clusters.\n",
    "\n",
    "\n",
    "(a)\n",
    "(b)\n",
    "(c)\n",
    "\n",
    "Figure 3: For Question 5.\n",
    "\n",
    "- Complete linkage: distance between clusters is the maximum distance between any pair of points from two clusters.\n",
    "- Average linkage: distance between clusters is the average distance between any pair of points from two clusters.\n",
    "\n",
    "(a) Which of the three types of linkage described above would most likely result in clusters most similar to those given by $k$-means?\n",
    "\n",
    "[3 marks]\n",
    "\n",
    "(b) Consider the data in Figure 3 (a). What would be the result if we extract 2 clusters from the tree given by hierarchical clustering on this dataset using single linkage? Describe your answer in terms of the labels 1-4 given to the four \"clumps\" in the data. Do the same for complete linkage and average linkage.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "(c) Which of the three types of linkage (if any) would successfully separate the two \"moons\" in Figure 3 (b)? What about Figure 3 (c)? Briefly explain your answers.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "\n",
    "## Bayes Classifier\n",
    "\n",
    "3. (2020) (a) In classification, the loss function we usually want to minimize is the $0 / 1$ loss:\n",
    "\n",
    "$$\n",
    "\\ell(f(X), Y))=I(f(X) \\neq Y)\n",
    "$$\n",
    "\n",
    "where $I(\\cdot)$ denotes an indicator function, which is one if the statement in $(\\cdot)$ is true and 0 otherwise. Choose the label $Y \\sim$ Bernoulli(1/2), which is 1 with probability $1 / 2$. If $Y=1, X \\sim \\operatorname{Bernoulli}(p)$, which is 1 with probability $p$. If $Y=0, X \\sim \\operatorname{Bernoulli}(q)$. Suppose that $p>q$. What is the Bayes optimal classifier and what is its risk?\n",
    "\n",
    "[7 marks]\n",
    "(b) In the following problem, we will consider the effect of using an asymmetric loss function:\n",
    "\n",
    "$$\n",
    "\\ell_{\\alpha, \\beta}(f(X), Y)=\\alpha I(f(X)=1, Y=0)+\\beta I(f(X)=0, Y=1)\n",
    "$$\n",
    "\n",
    "Under this loss function, the two types of errors receive different weights, determined by $\\alpha, \\beta>0$.\n",
    "\n",
    "i. What is the Bayes optimal classifier?\n",
    "\n",
    "[7 marks]\n",
    "\n",
    "ii. Suppose that class $Y=0$ is extremely uncommon, that is $P(Y=0)$ is small. This means $f(x)=1$ for all $x$ will have good risk. We may try to put the two classes on the same footing by considering the risk:\n",
    "\n",
    "$$\n",
    "R=P(f(X)=1 \\mid Y=0)+P(f(X)=0 \\mid Y=1)\n",
    "$$\n",
    "\n",
    "Show how $R$ is equivalent to the risk where the loss function is $\\ell_{\\alpha, \\beta}$ with certain choices of $\\alpha$ and $\\beta$.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "\n",
    "4. (2021) (a) Consider the following binary classification problem, $Y=0$ (class 1 ) or 1 (class 2). Suppose that $X \\in[0,1]$ with uniform distribution on $[0,1]$ and\n",
    "\n",
    "$$\n",
    "P(Y=1 \\mid X=x)=2\\left|x-\\frac{1}{2}\\right|\n",
    "$$\n",
    "\n",
    "i. Find the expression for the Bayes classifier.\n",
    "\n",
    "ii. Calculate the Bayes risk $R^{*}$ for this classification task.\n",
    "\n",
    "[9 marks]\n",
    "\n",
    "(b) Consider a binary classification problem, $Y=0$ (Class 1) or 1 (Class 2) with twodimensional predictor variable $\\mathbf{X}$. The estimated mean vectors of two classes are $\\hat{\\boldsymbol{\\mu}}_{1}=(-1,-1)^{\\mathrm{T}}$ and $\\hat{\\boldsymbol{\\mu}}_{2}=(1,1)^{\\mathrm{T}}$, respectively. The estimated prior probabilities $\\hat{\\pi}_{1}$ and $\\hat{\\pi}_{2}$ are equal.\n",
    "\n",
    "i. Applying LDA, we estimate the covariance matrix by $\\widehat{\\boldsymbol{\\Sigma}}=\\left(\\begin{array}{ll}1 & \\rho \\\\ \\rho & 1\\end{array}\\right)$, where $0 \\leq \\rho<1$. Find the decision boundary as a function of $\\rho$.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "ii. Applying QDA, we estimate the covariance matrices of two classes by $\\hat{\\boldsymbol{\\Sigma}}_{1}=$ $\\left(\\begin{array}{cc}3 & 0 \\\\ 0 & 1 / 3\\end{array}\\right)$ and $\\hat{\\boldsymbol{\\Sigma}}_{2}=\\left(\\begin{array}{cc}1 / 3 & 0 \\\\ 0 & 3\\end{array}\\right)$, respectively. Find the decision rule and draw a sketch of it in a two-dimensional plane.\n",
    "\n",
    "[9 marks]\n",
    "\n",
    "\n",
    "## Smoothing Splines\n",
    "\n",
    "4. (2020) The smoothing spline aims to find $g(\\cdot)$ that minimizes the penalized residual sum of squares\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n}\\left(y_{i}-g\\left(x_{i}\\right)\\right)^{2}+\\lambda \\int\\left(g^{(2)}(t)\\right)^{2} d t\n",
    "$$\n",
    "\n",
    "where $\\left\\{\\left(x_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$ denote the observed values for the covariate and the response, $\\lambda \\geq 0$ is a smoothing parameter and $g^{(2)}$ represents the second derivative of $g$. Write $g(x)=$ $\\mathbf{b}(x)^{T} \\boldsymbol{\\theta}$, where $\\mathbf{b}(x)=\\left(b_{1}(x), \\ldots, b_{n}(x)\\right)^{T} \\in \\mathbb{R}^{n}$ is a $n$-dimensional basis function and $\\boldsymbol{\\theta}=\\left(\\theta_{1}, \\ldots, \\theta_{n}\\right)^{T} \\in \\mathbb{R}^{n}$. Let $\\mathbf{y}=\\left(y_{1}, \\ldots, y_{n}\\right)^{T}, \\mathbf{B} \\in \\mathbb{R}^{n \\times n}$ with its $i$-th row vector given by $\\mathbf{b}\\left(x_{i}\\right) \\in \\mathbb{R}^{n}$ and $\\boldsymbol{\\Omega}=\\int \\mathbf{b}^{(2)}(t) \\mathbf{b}^{(2)}(t)^{T} d t \\in \\mathbb{R}^{n \\times n}$ with $\\mathbf{b}^{(2)}(x)=\\left(b_{1}^{(2)}(x), \\ldots, b_{n}^{(2)}(x)\\right)^{T}$. It was shown in class that\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{g}}_{\\lambda}=\\mathbf{S}_{\\lambda} \\mathbf{y}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{S}_{\\lambda}=\\mathbf{B}\\left(\\mathbf{B}^{T} \\mathbf{B}+\\lambda \\boldsymbol{\\Omega}\\right)^{-1} \\mathbf{B}^{T}$.\n",
    "\n",
    "(a) Suppose that $\\mathbf{B}$ is invertible. Express $\\mathbf{S}_{\\lambda}=\\left(\\mathbf{I}_{n}+\\lambda \\mathbf{K}\\right)^{-1}$, where $\\mathbf{I}_{n}$ is a $n \\times n$ identity matrix. What is the expression for $\\mathbf{K}$ ?\n",
    "\n",
    "[5 marks]\n",
    "\n",
    "(b) For $\\mathbf{K}$, let its eigenvalues be $d_{1}, \\ldots, d_{n}$ with the corresponding orthonormal eigenvectors, $\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{n} \\in \\mathbb{R}^{n}$. Express $\\mathbf{S}_{\\lambda}$ in terms of $\\lambda$ and $\\left\\{\\left(d_{i}, \\mathbf{u}_{i}\\right)\\right\\}_{i=1}^{n}$.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "(c) Discuss how the smoothing spline fitted value, $\\widehat{\\mathrm{g}}_{\\lambda}$, differs from the fitted value by regressing $\\mathbf{y}$ on the orthonormal basis $\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{n}$.\n",
    "\n",
    "[6 marks]\n",
    "\n",
    "(d) Express the degrees of freedom $\\mathrm{df}_{\\lambda}=\\operatorname{trace}\\left(\\mathbf{S}_{\\lambda}\\right)$ in terms of $\\lambda$ and $\\left\\{d_{i}\\right\\}_{i=1}^{n}$. [ 6 marks]\n",
    "\n",
    "\n",
    "## k-Nearest Neighbours\n",
    "\n",
    "2. (2020) (a) i. Provide a 2-dimensional dataset where 1-nearest neighbour has lower LOOCV error than linear SVM.\n",
    "\n",
    "ii. Provide a 2-dimensional dataset where 1-nearest neighbour has higher LOOCV error than linear SVM.\n",
    "(b) Consider the $k$-nearest neighbours approach using Euclidean distance on the dataset shown in Figure 2. What are the Leave-One-Out Cross Validation (LOOCV) errors for the following cases? Briefly justify your answers.\n",
    "\n",
    "i. 1-nearest neighbour.\n",
    "\n",
    "ii. 3-nearest neighbours.\n",
    "\n",
    "Figure 2: For Question 2. (b)\n",
    "\n",
    "(c) Consider the following binary classification problem. At a data point $x$, the conditional probability of a class $Y=k, k \\in\\{0,1\\}$ is $p_{k}(x)=P(Y=k \\mid X=x)$. In terms of $p_{k}(x)$ and $p_{k}\\left(x^{\\prime}\\right)$ when $x^{\\prime}$ is the nearest neighbour of $x$, what is the 1-nearest neighbour error at $x$ ?\n",
    "\n",
    "[3 marks]\n",
    "\n",
    "## Misclassification Error and ROC Curves\n",
    "\n",
    "2. (2019) Consider a two-class classification problem, $Y \\in\\{0,1\\}$. A classifier is constructed as $\\widehat{G}(X)=I(\\widehat{p}(X)>r)$ for some user-chosen threshold $r \\in[0,1]$, where $\\widehat{p}(X) \\in(0,1)$ is the predicted probability for $Y=1$ given the input $X$ and $I(\\cdot)$ is the indicator function. The classifier is trained by minimizing the misclassification error of a training dataset $\\left\\{\\left(x_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$ with size $n=1000$ for $r=0.5$. The number of positive examples are $\\sum_{i=1}^{n} I\\left(Y_{i}=1\\right)=600$. Figure 1 plots a ROC curve for the classifier based on the training dataset, that is a plot of the true positive rate (TPR) vs the false positive rate (FPR) as $r$ varies.\n",
    "\n",
    "Figure 1: ROC curve for thresholds $r \\in[0,1]$.\n",
    "(a) A point corresponding to a specific value of $r$ is marked with a label $(\\mathrm{FPR}=0.66$, $\\mathrm{TPR}=0.82$ in Figure 1. Construct a confusion matrix for this value of $r$. [6 marks]\n",
    "\n",
    "(b) Express the misclassification error rate as a function of FPR and TPR. [6 marks]\n",
    "\n",
    "(c) It just so happens that this ROC curve is well approximately by the function $\\mathrm{TPR}=$ $\\sqrt{\\mathrm{FPR}}$. Using this approximation, compute the FPR for the threshold value $r=0.5$. [5 marks]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem presented involves classifying the performance of a student, either as passing or failing, based on the number of sleeping hours ($X$) and a measure of laziness ($Z$). Here's the breakdown of the problem and the solution provided for part (i):\n",
    "\n",
    "### Problem Setting:\n",
    "- The classification rule is $Y = 1$ (pass) if $X + Z \\leq 12$, and $Y = 0$ (fail) otherwise.\n",
    "- The variables $X$ (sleeping hours) and $Z$ (laziness measure) are both uniformly distributed over the interval $[0,10]$, and they are independent of each other.\n",
    "\n",
    "### Objective for Part (i):\n",
    "To find the expression for the Bayes classifier with respect to $X$, you need to derive the classifier that minimizes the probability of misclassification based on the value of $X$ alone.\n",
    "\n",
    "### Solution Explanation:\n",
    "#### Step 1: Calculate $\\eta(x)$\n",
    "$\\eta(x)$ is defined as the conditional probability that $Y = 1$ given $X = x$. This translates mathematically to:\n",
    "$$\n",
    "\\eta(x) = P(Y = 1 \\mid X = x) = P(X + Z \\leq 12 \\mid X = x) = P(Z \\leq 12 - X \\mid X = x).\n",
    "$$\n",
    "\n",
    "#### Step 2: Considering the Range of $X$ and $Z$\n",
    "Since $X$ and $Z$ are independent and uniformly distributed on $[0, 10]$, the density of $Z$ given any value of $X = x$ remains uniform over $[0, 10]$. Therefore, the probability of $Z \\leq 12 - X$ is straightforward to compute:\n",
    "- If $12 - X \\geq 10$, i.e., $X \\leq 2$, then $Z \\leq 12 - X$ happens with probability 1 because $Z$ can only take values up to 10.\n",
    "- If $2 < X \\leq 10$, the probability is $\\frac{12 - X}{10}$ because $Z$ needs to be less than $12 - X$, and this ratio follows from the uniform distribution of $Z$ over $[0, 10]$.\n",
    "\n",
    "#### Step 3: Bayes Classifier\n",
    "To minimize the probability of misclassification:\n",
    "- If $\\eta(x) \\geq 0.5$, classify as $Y = 1$; otherwise, classify as $Y = 0$.\n",
    "- From the calculated $\\eta(x)$:\n",
    "  - For $0 \\leq x \\leq 2$, $\\eta(x) = 1$ (classify as $Y=1$).\n",
    "  - For $2 < x \\leq 10$, $\\eta(x) = \\frac{12-x}{10}$:\n",
    "    - When $x = 7$, $\\eta(7) = \\frac{5}{10} = 0.5$.\n",
    "    - For $x < 7$, $\\eta(x) > 0.5$; hence classify as $Y=1$.\n",
    "    - For $x > 7$, $\\eta(x) < 0.5$; hence classify as $Y=0$.\n",
    "\n",
    "#### Conclusion:\n",
    "The Bayes classifier classifies a student as passing ($Y=1$) if $0 \\leq x \\leq 7$ and failing ($Y=0$) if $x > 7$. This decision rule minimizes the probability of misclassification based on the information available from $X$ alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the Bayes risk $R^*$ for the classification task, we begin by understanding the Bayes risk conceptually:\n",
    "\n",
    "### Bayes Risk\n",
    "The Bayes risk $R^*$ is the minimum expected probability of error for a classification system under the Bayesian framework. It's calculated using the expression:\n",
    "$$\n",
    "R^* = \\mathbb{E}[\\min\\{\\eta(X), 1 - \\eta(X)\\}],\n",
    "$$\n",
    "where $\\eta(x)$ is the conditional probability of $Y=1$ given $X=x$, as derived in part (i). This expectation is effectively an integral over the possible values of $X$, weighted by their likelihood.\n",
    "\n",
    "### Calculating $R^*$\n",
    "Given that $X$ is uniformly distributed over $[0,10]$, each value of $X$ is equally likely, so the density function for $X$ is constant at $\\frac{1}{10}$. The risk calculation then becomes an integral over the range of $X$, considering the minimum of $\\eta(x)$ and $1 - \\eta(x)$, the misclassification probabilities.\n",
    "\n",
    "#### Recall:\n",
    "From part (i), we derived:\n",
    "$$\n",
    "\\eta(x) = \n",
    "\\begin{cases} \n",
    "1 & \\text{for } 0 \\leq x \\leq 2 \\\\\n",
    "\\frac{12 - x}{10} & \\text{for } 2 < x \\leq 10\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### Steps:\n",
    "1. **Calculate $\\min\\{\\eta(x), 1 - \\eta(x)\\}$ over the intervals of $x$**:\n",
    "   - For $0 \\leq x \\leq 2$, $\\eta(x) = 1$, hence $\\min\\{\\eta(x), 1 - \\eta(x)\\} = 1 - 1 = 0$.\n",
    "   - For $2 < x \\leq 7$, $\\eta(x) = \\frac{12 - x}{10}$, and since $\\eta(x) \\geq 0.5$, $\\min\\{\\eta(x), 1 - \\eta(x)\\} = 1 - \\eta(x)$.\n",
    "   - For $7 < x \\leq 10$, $\\eta(x) < 0.5$, hence $\\min\\{\\eta(x), 1 - \\eta(x)\\} = \\eta(x)$.\n",
    "\n",
    "2. **Perform the Integration**:\n",
    "$$\n",
    "R^* = \\int_2^7 \\frac{1}{10} (1 - \\eta(x)) dx + \\int_7^{10} \\frac{1}{10} \\eta(x) dx\n",
    "$$\n",
    "\n",
    "   Expanding $\\eta(x)$ in the integrals:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R^* & = \\int_2^7 \\frac{1}{10} \\left(1 - \\frac{12 - x}{10}\\right) dx + \\int_7^{10} \\frac{1}{10} \\left(\\frac{12 - x}{10}\\right) dx \\\\\n",
    "& = \\int_2^7 \\frac{1}{10} \\left(\\frac{x - 2}{10}\\right) dx + \\int_7^{10} \\frac{1}{10} \\left(\\frac{12 - x}{10}\\right) dx\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "   Simplifying these integrals and evaluating them:\n",
    "\n",
    "#### For $\\int_2^7 \\frac{x - 2}{100} dx$:\n",
    "$$\n",
    "\\frac{1}{100} \\left[\\frac{x^2}{2} - 2x \\right]_2^7 = \\frac{1}{100} \\left[ \\frac{49}{2} - 14 - (\\frac{4}{2} - 4) \\right] = \\frac{1}{100} \\left[ \\frac{25}{2} \\right] = \\frac{25}{200}\n",
    "$$\n",
    "\n",
    "#### For $\\int_7^{10} \\frac{12 - x}{100} dx$:\n",
    "$$\n",
    "\\frac{1}{100} \\left[ 12x - \\frac{x^2}{2} \\right]_7^{10} = \\frac{1}{100} \\left[ 120 - 50 - (84 - 24.5) \\right] = \\frac{1}{100} \\left[ 21 \\right] = \\frac{21}{200}\n",
    "$$\n",
    "\n",
    "Adding these two results gives the final Bayes risk:\n",
    "$$\n",
    "R^* = \\frac{25}{200} + \\frac{21}{200} = \\frac{46}{200} = \\frac{23}{100}.\n",
    "$$\n",
    "\n",
    "Therefore, the Bayes risk $R^*$, which quantifies the minimum expected probability of error, is $\\frac{23}{100}$ or 23%. This represents the theoretical\n",
    "\n",
    " lowest error rate achievable by any classifier for this problem under the given conditions and assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CT-editing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
